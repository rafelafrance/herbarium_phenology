{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f4130e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import textwrap\n",
    "from collections import namedtuple\n",
    "from datetime import date\n",
    "from pathlib import Path\n",
    "from pprint import pp\n",
    "\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact\n",
    "from PIL import Image, ImageColor, ImageDraw, ImageFont\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "from herbarium.pylib import db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dec54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = Path('..') / 'data'\n",
    "\n",
    "DB = DATA / 'angiosperms.sqlite'\n",
    "IMAGES = DATA / 'images'\n",
    "TEMP = DATA / 'temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc52808e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TODAY = date.today().isoformat()\n",
    "\n",
    "FIELDS = [\n",
    "    ('reproductivecondition', 'reproductive condition'),\n",
    "    ('occurrenceremarks', 'occurrence remarks'),\n",
    "    ('fieldnotes', 'field notes'),\n",
    "    ('dynamicproperties', 'dynamic properties'),\n",
    "]\n",
    "\n",
    "FLOWERING = db.select_tests(DB, 'b0_flowers_all_orders_1')\n",
    "FRUITING = db.select_tests(DB, 'b0_fruits_all_orders_1')\n",
    "LEAF_OUT = db.select_tests(DB, 'b0_leaf_out_all_orders_1')\n",
    "\n",
    "TEST_SETS = (FLOWERING, FRUITING, LEAF_OUT)\n",
    "\n",
    "ORDERS = db.select_all_orders(DB)\n",
    "\n",
    "TRAITS = [\n",
    "    ('flowering', FLOWERING),\n",
    "    ('fruiting', FRUITING),\n",
    "    ('leaf_out', LEAF_OUT),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37480313",
   "metadata": {},
   "source": [
    "# Confusion matrix per order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267baf07",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_order = []\n",
    "\n",
    "for trait_name, test_set in TRAITS:\n",
    "    for order in ORDERS:\n",
    "        order_recs = [r for r in test_set if r['order_'] == order]\n",
    "        if not order_recs:\n",
    "            continue\n",
    "        per_order.append({\n",
    "            'trait': trait_name,\n",
    "            'order': order,\n",
    "            'true_pos': sum(1 for r in order_recs if r['target'] == 1 and round(r['pred']) == 1),\n",
    "            'true_neg': sum(1 for r in order_recs if r['target'] == 0 and round(r['pred']) == 0),\n",
    "            'false_pos': sum(1 for r in order_recs if r['target'] == 0 and round(r['pred']) == 1),\n",
    "            'false_neg': sum(1 for r in order_recs if r['target'] == 1 and round(r['pred']) == 0),\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83754e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(per_order)\n",
    "path = TEMP / f'results_per_order_{TODAY}.csv'\n",
    "df.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4cbbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8deae095",
   "metadata": {},
   "source": [
    "## Per trait confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dcc879",
   "metadata": {},
   "outputs": [],
   "source": [
    "for trait, test_set in TRAITS:\n",
    "    tp = [r for r in test_set if r['target'] == 1 and round(r['pred']) == 1]\n",
    "    tn = [r for r in test_set if r['target'] == 0 and round(r['pred']) == 0]\n",
    "    fp = [r for r in test_set if r['target'] == 0 and round(r['pred']) == 1]\n",
    "    fn = [r for r in test_set if r['target'] == 1 and round(r['pred']) == 0]\n",
    "\n",
    "    targets = pd.Series([round(r['target']) for r in test_set])\n",
    "    preds = pd.Series([round(r['pred']) for r in test_set])\n",
    "\n",
    "    df_confusion = pd.crosstab(\n",
    "        targets, preds, rownames=['Actual'], colnames=['Predicted'])\n",
    "\n",
    "    print('=' * 80)\n",
    "    print(trait[0])\n",
    "    print(df_confusion)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225cf979",
   "metadata": {},
   "source": [
    "## Display output results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e5bbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD = 8\n",
    "BLACK = 'black'\n",
    "GRAY = '#eeeeee'\n",
    "\n",
    "Text = namedtuple('Text', 'x y bbox text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab81e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "indent = ' ' * 24\n",
    "\n",
    "def build_text(draw, font, texts, text, x, y):\n",
    "    for t in textwrap.wrap(text, subsequent_indent=indent):\n",
    "        bbox = draw.textbbox((0, 0), t, font, anchor='lt')\n",
    "        texts.append(Text(x, y, bbox, t))\n",
    "        y += bbox[3] + PAD\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ee0585",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(idx, trait, dataset, confusion, dir_):\n",
    "    rec = test_set[idx - 1]\n",
    "    image = Image.open(Path('..') / rec['path'])\n",
    "\n",
    "    font = ImageFont.truetype(\n",
    "        str(DATA / 'fonts' / 'SourceCodePro-Regular.ttf'), 64)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    texts = []\n",
    "\n",
    "    x, y = 10, 10\n",
    "    w, h = image.size\n",
    "\n",
    "    text = f'{\"confusion:\":<23} {confusion}'\n",
    "    y = build_text(draw, font, texts, text, x, y)\n",
    "\n",
    "    text = f'{\"coreid:\":<23} {rec[\"coreid\"]}'\n",
    "    y = build_text(draw, font, texts, text, x, y)\n",
    "\n",
    "    for field, label in FIELDS:\n",
    "        text = f'{(label+\":\"):<23} {rec[field]}'\n",
    "        y = build_text(draw, font, texts, text, x, y)\n",
    "\n",
    "    flag = '1' if rec['target'] == 1 else '0'\n",
    "\n",
    "    text = f'{trait + \" NLP:\":<23} {flag}'\n",
    "    y = build_text(draw, font, texts, text, x, y)\n",
    "\n",
    "    text = f'{trait + \" model:\":<23} {round(rec[\"pred\"])} ({rec[\"pred\"]:0.4})'\n",
    "    y = build_text(draw, font, texts, text, x, y)\n",
    "\n",
    "    max_x = max(t.bbox[2] for t in texts)\n",
    "    draw.rectangle((0, 0, max_x + 32, y + 32), fill=GRAY)\n",
    "\n",
    "    for t in texts:\n",
    "        draw.text((t.x, t.y), t.text, BLACK, font=font)\n",
    "\n",
    "    path = dir_ / f'{rec[\"coreid\"]}.jpg'\n",
    "    image.save(path, 'JPEG')\n",
    "\n",
    "    # display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUNT = 100\n",
    "\n",
    "for trait, test_set in TRAITS:\n",
    "    tp = [r for r in test_set if r['target'] == 1 and round(r['pred']) == 1]\n",
    "    tn = [r for r in test_set if r['target'] == 0 and round(r['pred']) == 0]\n",
    "    fp = [r for r in test_set if r['target'] == 0 and round(r['pred']) == 1]\n",
    "    fn = [r for r in test_set if r['target'] == 1 and round(r['pred']) == 0]\n",
    "\n",
    "    datasets = [('true_pos', tp), ('true_neg', tn),\n",
    "                ('false_pos', fp), ('false_neg', fn)]\n",
    "\n",
    "    for confusion, dataset in datasets:\n",
    "        dir_ = DATA / 'temp' / f'{trait}_{TODAY}' / confusion\n",
    "        dir_.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        for i, _ in tqdm(enumerate(dataset[:COUNT], 1)):\n",
    "            display_image(i, trait, dataset, confusion, dir_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb4e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
